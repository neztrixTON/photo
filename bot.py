import logging
import tempfile
import requests
import re
import io
import json
import pandas as pd
from urllib.parse import urlparse
from bs4 import BeautifulSoup
from telegram import (
    Update,
    InlineKeyboardMarkup,
    InlineKeyboardButton,
    InputFile,
)
from telegram.constants import ParseMode, ChatAction
from telegram.ext import (
    Application,
    MessageHandler,
    filters,
    CallbackQueryHandler,
    ContextTypes,
    CommandHandler,
)

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.DEBUG  # DEBUG, —á—Ç–æ–±—ã –≤–∏–¥–µ—Ç—å –≤—Å–µ —à–∞–≥–∏
)
logger = logging.getLogger(__name__)

# === –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
YANDEX_UPLOAD_URL = (
    'https://yandex.ru/images-apphost/image-download'
    '?cbird=111&images_avatars_size=preview&images_avatars_namespace=images-cbir'
)
YANDEX_SEARCH_URL = 'https://yandex.ru/images/search'
RESULTS_PER_PAGE = 10
HEADERS_UPLOAD = {
    'Accept': '*/*',
    'Accept-Language': 'ru,en;q=0.9',
    'Content-Type': 'image/jpeg',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) '
                  'AppleWebKit/537.36 (KHTML, like Gecko) '
                  'Chrome/134.0.0.0 YaBrowser/25.4.0.0 Safari/537.36'
}

SKIP_DOMAINS = [
    'avatars.mds.yandex.net',
    'yastatic.net',
    'info-people.com',
    'yandex.ru/support/images',
    'passport.yandex.ru',
]

MARKET_DOMAINS = {
    'ozon.ru': 'Ozon',
    'megamarket.ru': 'Megamarket',
    'wildberries.ru': 'Wb',
    'wb.ru': 'Wb',
    'market.yandex.ru': 'Yandex Market',
    'market.ya.ru': 'Yandex Market',
}

# === –•—ç–Ω–¥–ª–µ—Ä—ã ===
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∫–∞—Ä—Ç–∏–Ω–∫—É, –∏ —è –Ω–∞–π–¥—É –ø–æ—Ö–æ–∂–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

    photo = await update.message.photo[-1].get_file()
    with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as tf:
        await photo.download_to_drive(tf.name)
        image_path = tf.name
    logger.debug(f"–§–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {image_path}")

    try:
        all_links, market_links = search_by_image(image_path)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(all_links)} –æ–±—â–∏—Ö —Å—Å—ã–ª–æ–∫, {len(market_links)} –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤")
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ search_by_image")
        all_links, market_links = [], []

    context.user_data.update({
        'all_links': all_links,
        'market_links': market_links,
        'page_all': 0,
        'page_market': 0,
        'mode': 'all'
    })
    await display_links(update, context)

# === –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
async def display_links(update, context):
    chat_id = update.effective_chat.id
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.TYPING)

    mode = context.user_data['mode']
    page = context.user_data[f'page_{mode}']
    links = context.user_data['all_links'] if mode == 'all' else context.user_data['market_links']
    total = len(links)
    start = page * RESULTS_PER_PAGE
    subset = links[start:start + RESULTS_PER_PAGE]

    text = (format_links(subset, page, total) if mode == 'all'
            else format_market_links(subset, page, total))
    keyboard = build_keyboard(page, total)

    if update.callback_query:
        msg = update.callback_query.message
        await msg.edit_text(text, reply_markup=keyboard,
                            disable_web_page_preview=True, parse_mode=ParseMode.HTML)
        await update.callback_query.answer()
    else:
        await update.message.reply_text(text, reply_markup=keyboard,
                                        disable_web_page_preview=True, parse_mode=ParseMode.HTML)

async def save_excel(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.effective_chat.id
    await context.bot.send_chat_action(chat_id=chat_id, action=ChatAction.UPLOAD_DOCUMENT)

    all_links = context.user_data.get('all_links', [])
    market_links = context.user_data.get('market_links', [])
    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
        pd.DataFrame({'–°—Å—ã–ª–∫–∞': all_links}).to_excel(writer, index=False, sheet_name='–û–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã')
        pd.DataFrame({'–°—Å—ã–ª–∫–∞': market_links}).to_excel(writer, index=False, sheet_name='–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã')
    buffer.seek(0)

    await update.callback_query.message.reply_document(
        document=InputFile(buffer, filename='results.xlsx'),
        caption='–§–∞–π–ª Excel —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏'
    )
    await update.callback_query.answer()

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    data = update.callback_query.data
    logger.debug(f"–ù–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞: {data}")
    if data in ['show_all', 'show_market']:
        context.user_data['mode'] = 'all' if data == 'show_all' else 'market'
    elif data in ['prev', 'next']:
        mode = context.user_data['mode']
        key = f'page_{mode}'
        context.user_data[key] += 1 if data == 'next' else -1
    elif data == 'save_excel':
        await save_excel(update, context)
        return
    await display_links(update, context)

async def error_handler(update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.exception("Exception while handling an update")

# === –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ===
def build_keyboard(page, total):
    buttons, nav = [], []
    if page > 0:
        nav.append(InlineKeyboardButton('‚¨ÖÔ∏è –ù–∞–∑–∞–¥', callback_data='prev'))
    if (page + 1) * RESULTS_PER_PAGE < total:
        nav.append(InlineKeyboardButton('–í–ø–µ—Ä—ë–¥ ‚û°Ô∏è', callback_data='next'))
    if nav:
        buttons.append(nav)
    buttons.append([
        InlineKeyboardButton('–û–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã', callback_data='show_all'),
        InlineKeyboardButton('–ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã', callback_data='show_market'),
    ])
    buttons.append([InlineKeyboardButton('üíæ –í Excel', callback_data='save_excel')])
    return InlineKeyboardMarkup(buttons)

def format_links(urls, page, total):
    header = f"üñº –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page+1}/{(total-1)//RESULTS_PER_PAGE+1}\n"
    lines = [f"{i}. üîó <a href=\"{url}\">–°—Å—ã–ª–∫–∞ {i}</a>"
             for i, url in enumerate(urls, start=page*RESULTS_PER_PAGE+1)]
    return header + "\n".join(lines)

def format_market_links(urls, page, total):
    header = f"üõí –ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã {page+1}/{(total-1)//RESULTS_PER_PAGE+1}\n"
    lines = []
    for i, url in enumerate(urls, start=page*RESULTS_PER_PAGE+1):
        domain = urlparse(url).netloc
        name = next((label for key, label in MARKET_DOMAINS.items() if domain.endswith(key)), domain)
        lines.append(f"{i}. üîó <a href=\"{url}\">–°—Å—ã–ª–∫–∞ {i}</a> ({name})")
    return header + "\n".join(lines)

# === –û—Å–Ω–æ–≤–Ω–∞—è –ø–æ–∏—Å–∫–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ª–æ–≥–∞–º–∏ ===
def search_by_image(image_path):
    from html import unescape

    logger.debug("=== –ü–æ–∏—Å–∫ –ø–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é ===")
    # 1) upload
    logger.debug("1) –ó–∞–≥—Ä—É–∑–∫–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞ Yandex")
    with open(image_path, 'rb') as f:
        resp = requests.post(YANDEX_UPLOAD_URL, headers=HEADERS_UPLOAD, data=f)
    logger.debug(f"Upload response code: {resp.status_code}")
    resp.raise_for_status()
    data = resp.json()
    logger.debug(f"Upload JSON: {data}")
    cbir_id = data.get('cbir_id')
    orig = data.get('sizes', {}).get('orig', {}).get('path')
    if not cbir_id or not orig:
        logger.error("–ù–µ –ø–æ–ª—É—á–∏–ª–∏ cbir_id –∏–ª–∏ orig –≤ –æ—Ç–≤–µ—Ç–µ upload")
        return [], []

    # 2) –ø–æ–ª—É—á–µ–Ω–∏–µ HTML
    logger.debug(f"2) –ó–∞–ø—Ä–æ—Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å–∞–π—Ç–æ–≤ (cbir_id={cbir_id})")
    params = {
        'cbir_id': cbir_id,
        'cbir_page': 'sites',
        'rpt': 'imageview',
        'url': orig,
    }
    resp = requests.get(YANDEX_SEARCH_URL, params=params, headers={'User-Agent': HEADERS_UPLOAD['User-Agent']})
    logger.debug(f"Search response code: {resp.status_code}, URL: {resp.url}")
    resp.raise_for_status()
    html = resp.text
    logger.debug(f"–ü–æ–ª—É—á–∏–ª–∏ HTML –¥–ª–∏–Ω–æ–π {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
    soup = BeautifulSoup(html, 'html.parser')

    links = []

    # 3) JSON –≤ data-state
    logger.debug("3) –ü–∞—Ä—Å–∏–º JSON –∏–∑ data-state")
    root = soup.select_one('div.Root[data-state]')
    if root:
        raw = unescape(root['data-state'])
        logger.debug(f"Raw data-state JSON length: {len(raw)}")
        try:
            state = json.loads(raw)
            sites = state.get('sites', [])
            logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(sites)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ state['sites']")
            for item in sites:
                url = item.get('url') or item.get('link')
                if url and url not in links:
                    links.append(url)
        except json.JSONDecodeError as e:
            logger.exception("JSONDecodeError –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ data-state")

    # 4) –§–æ–ª–ª–±—ç–∫ —á–µ—Ä–µ–∑ HTML
    logger.debug("4) HTML-—Ñ–æ–ª–ª–±—ç–∫ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º .CbirSites-ItemInfo")
    for info in soup.select('.CbirSites-ItemInfo'):
        a_dom = info.select_one('.CbirSites-ItemDomain a')
        if a_dom and a_dom.has_attr('href'):
            url = a_dom['href']
        else:
            a_title = info.select_one('.CbirSites-ItemTitle a')
            url = a_title['href'] if a_title and a_title.has_attr('href') else None
        if url and url not in links:
            links.append(url)
    logger.debug(f"–ü–æ—Å–ª–µ —Ñ–æ–ª–ª–±—ç–∫–∞ –≤—Å–µ–≥–æ —Å—Å—ã–ª–æ–∫: {len(links)}")

    # 5) –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    logger.debug("5) –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–æ–º–µ–Ω–æ–≤ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π")
    clean = []
    for link in links:
        domain = urlparse(link).netloc
        if any(skip in domain for skip in SKIP_DOMAINS):
            continue
        if re.search(r"\.(css|js|jpg|jpeg|png|webp|gif)(?:$|\?)", link.lower()):
            continue
        clean.append(link)
    logger.debug(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–æ—Å—å: {len(clean)}")

    # 6) –î–µ–¥—É–ø
    seen, unique = set(), []
    for link in clean:
        if link not in seen:
            seen.add(link)
            unique.append(link)
    logger.debug(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –≤—Å–µ–≥–æ: {len(unique)}")

    # 7) –ú–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã
    market = [l for l in unique if any(urlparse(l).netloc.endswith(key) for key in MARKET_DOMAINS)]
    logger.debug(f"–°—Å—ã–ª–æ–∫ –Ω–∞ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã: {len(market)}")
    return unique, market

def main():
    application = Application.builder().token('8037946874:AAFt8VjAfy-UpTXF-XoJUYPiNlC7B-btUms').build()
    application.add_handler(CommandHandler('start', start))
    application.add_handler(MessageHandler(filters.PHOTO, handle_photo))
    application.add_handler(CallbackQueryHandler(button_callback))
    application.add_error_handler(error_handler)
    application.run_polling()

if __name__ == '__main__':
    main()
